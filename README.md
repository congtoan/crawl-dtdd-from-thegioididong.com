# Crawl Mobile Listings from TheGioiDiDong.com

This repository contains Python scripts to crawl mobile phone listings and detailed product information from the website thegioididong.com. The scripts extract phone listings based on brand names and price ranges, and then scrape detailed information about individual products. All the scraped data is exported into Excel files for further analysis.

## Features

### `crawl_dtdd.py`
- Scrapes mobile phone listings for different brands and price ranges.
- Extracts the `href` link and `data-name` attribute for each phone listing.
- Saves the extracted data into an Excel file (`tgdd_phone_data.xlsx`).
- Customizable for additional brands or price ranges.

### `crawl_product_detail.py`
- Reads URLs from the Excel file generated by `crawl_dtdd.py`.
- Visits each phone’s URL to scrape detailed product information, including:
  - **Brand (Hãng)**: The phone's brand.
  - **Current Price (Giá bán)**: The listed selling price.
  - **Original Price (Giá gốc)**: The original price, if available.
  - **Discount Percentage (Mức giảm giá)**: The discount percentage, if any.
  - **Screen (Màn hình)**: The display specifications.
  - **Operating System (Hệ điều hành)**: The OS used by the phone.
  - **Rear Camera (Camera sau)**: Details of the rear camera setup.
  - **Front Camera (Camera trước)**: Details of the front camera setup.
  - **Chip (Chip)**: The processor/chipset powering the phone.
  - **RAM (RAM)**: The amount of RAM.
  - **Storage (Dung lượng lưu trữ)**: Internal storage capacity.
  - **SIM (SIM)**: SIM card support and specifications.
  - **Battery & Charging (Pin, Sạc)**: Information on battery capacity and charging technology.
- Exports all product details to a new Excel file (`product_detail_output.xlsx`).

## Price Ranges
The tool crawls phones from the following price ranges:
- **Under 2 million VND** (`duoi-2-trieu`)
- **2-4 million VND** (`tu-2-4-trieu`)
- **4-7 million VND** (`tu-4-7-trieu`)
- **7-13 million VND** (`tu-7-13-trieu`)
- **13-20 million VND** (`tu-13-20-trieu`)
- **Above 20 million VND** (`tren-20-trieu`)

## Brands Crawled
The tool is currently set up to crawl the following mobile phone brands:
- Samsung
- Apple (iPhone)
- OPPO
- Xiaomi
- Vivo
- Realme
- Honor
- TCL
- Tecno
- Nokia
- Masstel
- Mobell
- Itel

## Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/congtoan/crawl-dtdd-from-thegioididong.com.git
   cd crawl-dtdd-from-thegioididong.com

2. **Crawl phone listings**:
First, run the crawl_dtdd.py script to scrape the phone listings by brand and price range. This will save the scraped data (including URLs) into tgdd_phone_data.xlsx.
   ```bash
   python crawl_dtdd.py

3. **Crawl product details**:
After running the first script, run crawl_product_detail.py to visit each phone’s URL and scrape detailed product information. This will generate an Excel file with all the scraped details.
   ```bash
   python crawl_product_detail.py
The output will be saved to product_detail_output.xlsx.

## Optimization

This code is a demo using basic web scraping techniques. For large-scale data scraping or handling different page layouts on **thegioididong.com**, the following optimizations are needed:

- **Handling Dynamic Content**: Some pages may load content dynamically using JavaScript. Implement solutions like Selenium or headless browsers (e.g., Puppeteer) to scrape these pages.
  
- **Error Handling and Retry Logic**: Add proper error handling for network issues, missing elements, or pages with different structures. Implement retry logic for failed requests to ensure complete data scraping.

- **Efficient Scraping**: For large volumes of data, consider adding delays between requests, rotating user-agents, and using proxies to prevent being blocked.

- **Parallel Processing**: Utilize parallel processing libraries like `multiprocessing` or `asyncio` to scrape multiple pages concurrently, speeding up the data collection process.

- **Crawling Strategy**: To adapt to changes in the page layout, regularly update the parsing logic based on the current structure of the website.

By implementing these optimizations, the script will be better suited for large-scale and long-term use.
